# AI-Powered Medical Call Agent ğŸ¥ ğŸ¤–

A comprehensive, real-time AI voice agent designed for healthcare. It handles appointments, facilitates doctor-patient connections, and manages critical emergencies with geospatial intelligence and zero-latency routing.

---

## ğŸ“‹ Project Overview

This Final Year Project (FYP) implements an **AI-powered voice assistant** that can:
- Answer incoming phone calls automatically
- Understand natural language speech using OpenAI GPT-4
- Classify caller intents (appointments, prescriptions, emergencies, doctor search)
- Respond with empathetic, contextual voice responses via Twilio
- Route critical emergencies to appropriate services (911/1122/999)
- Provide a real-time dashboard for operators to monitor calls

---

## ğŸš€ Key Features

### ğŸŒŸ Core Modules
| Module | Description |
|--------|-------------|
| **Dashboard** | Real-time call monitoring with live transcripts via WebSockets |
| **Appointments** | Full scheduling system (list/detail views) for upcoming, past, and cancelled visits |
| **Doctors Directory** | Manage medical staff profiles, specializations, and availability. **Geospatial-enabled** for location-based searches |
| **Patient CRM** | Detailed patient history, medical records, allergies, and interaction logs |
| **Analytics** | Visual insights into call volume, intent distribution, and emergency statistics |
| **Settings** | Configurable clinic settings and system preferences |

### ğŸš¨ Emergency Protocols (Real-World Ready)

| Phase | Trigger | Action |
|-------|---------|--------|
| **Phase 1: Geospatial Intelligence** | User mentions location (e.g., "I'm in Clifton") | Extract location, query database for nearby doctors using **MongoDB $near** |
| **Phase 2: Dynamic Routing** | AI detects `severity: critical` | Route based on caller country: **USâ†’911**, **PKâ†’1122**, **GBâ†’999** |
| **Phase 3: Zero-Latency Handoff** | Keywords: "dying", "shot", "heart stopped" | Bypass AI entirely, connect in **< 2 seconds** |

### âš¡ Real-Time Interaction
- **Barge-In Support**: Callers can interrupt the AI naturally (full-duplex conversation)
- **Live Dashboard**: Watch calls appear instantly via WebSockets
- **Auto-Redirect**: Dashboard automatically focuses on active calls
- **Live Transcript**: Watch conversations unfold textually in real-time

---

## ğŸ› ï¸ Technology Stack

| Layer | Technology |
|-------|------------|
| **Frontend** | Next.js 16, React 19, Tailwind CSS v4, shadcn/ui |
| **Backend** | Next.js API Routes (Serverless), MongoDB (with Geospatial Indexes) |
| **Real-time** | Socket.io (WebSockets) for live dashboard updates |
| **Voice/Telephony** | Twilio Voice API (TwiML, enhanced speech models, `Polly.Joanna-Neural`) |
| **AI/NLP** | OpenAI GPT-4 (Intent Classification, Emergency Detection, Response Generation) |
| **Authentication** | JWT-based login with role-based access (Admin/Operator) |

---

## ğŸ§  AI Modules

| Module | File | Purpose |
|--------|------|---------|
| **Intent Classifier** | `lib/ai/intent-classifier.ts` | Classifies speech into intents using GPT-4 |
| **Emergency Detector** | `lib/ai/emergency-detector.ts` | Analyzes transcripts for emergency severity (none â†’ critical) |
| **Response Generator** | `lib/ai/response-generator.ts` | Generates empathetic AI responses for callers |
| **Location Service** | `lib/ai/location-service.ts` | Extracts location and queries MongoDB for nearby doctors |

---

## ğŸ“Š Data Models

| Model | Key Fields |
|-------|------------|
| **User** | email, password (hashed), role (admin/operator), name |
| **Doctor** | name, specialization, availability, location (GeoJSON), address |
| **Patient** | name, phone, dateOfBirth, allergies, medicalHistory |
| **Appointment** | patientId, doctorId, dateTime, status, notes |
| **Call** | callSid, callerNumber, transcript, intent, priority, emergencyDetected, aiResponse |

---

## ğŸ”Œ API Endpoints

| Category | Endpoints |
|----------|-----------|
| **Authentication** | `/api/auth/login`, `/api/auth/logout`, `/api/auth/me` |
| **Twilio Webhooks** | `/api/twilio/voice`, `/api/twilio/process-speech`, `/api/twilio/status`, `/api/twilio/outbound` |
| **CRUD Operations** | `/api/appointments`, `/api/doctors`, `/api/patients`, `/api/calls`, `/api/users` |
| **Dashboard** | `/api/dashboard/stats` |

---

## ğŸ‡µğŸ‡° Data Pack: Karachi Edition

The system is seeded with a **Karachi, Pakistan** logic pack:
- **Doctors**: Real hospital names (Aga Khan, South City, NICVD)
- **Locations**: Coordinates centered on Karachi (Clifton, DHA, Gulshan)
- **Patients**: Local names and demographics

---

## ğŸš¦ Getting Started

### 1. Prerequisites
- Node.js 18+
- MongoDB (running locally or Atlas)
- Twilio Account (SID, Auth Token, Phone Number)
- OpenAI API Key
- ngrok (for local development with Twilio)

### 2. Installation
```bash
git clone https://github.com/your-repo/ai-call-agent.git
cd ai-call-agent
npm install
```

### 3. Environment Setup
Create a `.env.local` file:
```env
# Database
MONGODB_URI=mongodb://localhost:27017/ai-call-agent

# Auth
JWT_SECRET=your_secret_key

# Twilio
TWILIO_ACCOUNT_SID=...
TWILIO_AUTH_TOKEN=...
TWILIO_PHONE_NUMBER=...

# AI
OPENAI_API_KEY=sk-...

# App
NEXT_PUBLIC_APP_URL=https://your-ngrok-url.ngrok-free.app
```

### 4. Seed Data (Crucial!)
Populate the database with the Karachi Data Pack:
```bash
npx tsx scripts/seed-data.ts
```
*This creates 10 Doctors, 12 Patients, and 40 Appointments with valid geospatial data.*

### 5. Run Development Server
```bash
npm run dev
```

### 6. Production Build
```bash
npm run build
npm start
```

---

## ğŸ§ª Testing the Emergency Features

### Test Case 1: "Find a Doctor"
- **User**: "I need a heart specialist in Clifton."
- **AI**: Extracts "Clifton", queries DB for Cardiologists near coordinates, returns Dr. Ahmed at Aga Khan.

### Test Case 2: "Critical Emergency"
- **User**: "I'm having a heart attack! Help!"
- **AI**: Detects "heart attack" â†’ Severity Critical â†’ Checks country (PK) â†’ **Dials 1122 immediately**.

### Test Case 3: "Zero Latency"
- **User**: "Person shot! Dying!"
- **System**: Bypasses LLM â†’ **Connects to emergency services instantly**.

---

## ğŸ“ Project Structure

```
ai-call-agent/
â”œâ”€â”€ app/                    # Next.js App Router
â”‚   â”œâ”€â”€ api/               # API Routes
â”‚   â”‚   â”œâ”€â”€ twilio/        # Twilio webhooks
â”‚   â”‚   â”œâ”€â”€ calls/         # Call CRUD
â”‚   â”‚   â”œâ”€â”€ doctors/       # Doctor CRUD
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ dashboard/         # Main dashboard page
â”‚   â”œâ”€â”€ appointments/      # Appointments module
â”‚   â”œâ”€â”€ doctors/           # Doctors module
â”‚   â””â”€â”€ patients/          # Patients module
â”œâ”€â”€ lib/                   # Shared utilities
â”‚   â”œâ”€â”€ ai/               # AI modules
â”‚   â”‚   â”œâ”€â”€ intent-classifier.ts
â”‚   â”‚   â”œâ”€â”€ emergency-detector.ts
â”‚   â”‚   â”œâ”€â”€ response-generator.ts
â”‚   â”‚   â””â”€â”€ location-service.ts
â”‚   â”œâ”€â”€ mongodb.ts        # Database connection
â”‚   â”œâ”€â”€ openai-client.ts  # OpenAI integration
â”‚   â””â”€â”€ twilio-client.ts  # Twilio integration
â”œâ”€â”€ models/               # Mongoose-like schemas
â”œâ”€â”€ components/           # React UI components
â”œâ”€â”€ scripts/              # Seed and utility scripts
â””â”€â”€ public/               # Static assets
```

---

## ğŸ”® Future Roadmap
- [ ] Integration with Google Maps API for real-time traffic routing
- [ ] WhatsApp integration for appointment reminders
- [ ] Multi-lingual support (Urdu/English automatic detection)
- [ ] Voicemail transcription and callback scheduling

---

## ğŸ‘¥ Team
- **Developer**: [Your Name]
- **Supervisor**: [Supervisor Name]
- **Institution**: [University Name]

---

## ğŸ“„ License
FYP Project - Educational Use Only.

---

## ğŸ“ Demo

To test the system:
1. Start the server (`npm run dev` or `npm start`)
2. Expose via ngrok: `ngrok http 3000`
3. Configure Twilio webhook to: `https://your-ngrok-url/api/twilio/voice`
4. Call your Twilio number
5. Speak naturally and observe the AI respond!
